# Scraping Pipeline Metrics Definition

This document defines key metrics for monitoring the health, performance, and reliability of the web scraping pipeline. These metrics cover individual scrapers, ETL processes, the orchestration layer (Prefect), and underlying databases.

## 1. Introduction

Effective monitoring is crucial for maintaining a healthy data pipeline. These metrics will help in identifying issues proactively, understanding performance bottlenecks, ensuring data quality, and making informed decisions about scaling and maintenance.

## 2. Scraper-Level Metrics

These metrics are typically generated by individual scraper scripts or the classes they use (e.g., `SerpentScaleScraper` from `ventura_crawler.py`). They should be logged consistently and can be aggregated by a monitoring system or directly from logs/database.

| Metric Name                      | Description                                                                 | Source                                                                 | Use/Interpretation                                                                                                |
|----------------------------------|-----------------------------------------------------------------------------|------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|
| **Run Success/Failure Rate**     | Percentage of scraper runs that complete successfully versus those that fail. | Scraper logs, Orchestrator (Prefect flow status)                       | High failure rate indicates systemic issues (e.g., site changes, IP blocks, code bugs). Track per scraper.         |
| **URL Success Rate**             | Percentage of individual URLs successfully scraped vs. failed within a run. | Scraper logs, `ScrapingResult.success`                                 | Indicates issues with specific URL patterns, site sections, or intermittent errors.                               |
| **URLs Processed per Run**       | Total number of unique URLs a scraper attempts to process in a single run.  | Scraper logs, `ScrapingMetrics.total_urls_processed`                   | Baseline for throughput; changes can indicate issues with URL discovery or input.                               |
| **Items/Events Extracted per Run**| Total number of structured items (e.g., events) successfully extracted.     | Scraper logs, `ScrapingMetrics.total_events_extracted`, DB counts      | Tracks data yield. Sudden drops can indicate site changes or parsing logic failures.                            |
| **Average Page Load Time**       | Average time taken to load a page (navigation to content ready).            | Scraper logs, `ScrapingResult.response_time_ms`                        | Monitors site responsiveness and network latency. Increases can signal anti-scraping measures or network issues.  |
| **HTTP Error Counts (by Code)**  | Count of HTTP errors encountered, categorized by status code (e.g., 403, 404, 429, 5xx). | Scraper logs, `ScrapingResult.status_code`                             | 403/429 indicate blocking. 404 means URLs are invalid. 5xx indicate server-side issues on the target.        |
| **CAPTCHA Detections**           | Number of times a CAPTCHA is detected during a scraping run.                | Scraper logs, `CaptchaSolver` logic                                    | High counts indicate aggressive anti-scraping measures; may require better proxies or CAPTCHA solving.            |
| **Proxy Errors**                 | Number of errors related to proxy connections (e.g., connection failed, timeout). | Scraper logs, `AntiDetectionManager` logic                             | Indicates issues with the proxy pool quality or configuration.                                                  |
| **Extraction Errors**            | Count of errors during data extraction (e.g., selector not found, JSON parsing error, validation error). | Scraper logs, parsing logic exceptions                               | Points to outdated selectors, changes in page structure, or unexpected data formats.                            |
| **Cache Hit Rate**               | (For `ventura_crawler`) Percentage of URLs served from cache vs. live fetch. | `DatabaseManager.get_cached_result`, `ScrapingMetrics.cache_hits`      | High rate reduces load on target sites and speeds up scraping. Low rate means frequent live fetches.            |
| **Data Quality Score (Avg)**     | (If `QualityScorer` is used) Average quality score of extracted items.      | `QualityScorer` output                                                 | Tracks the reliability and completeness of the extracted data.                                                    |
| **Extraction Method Usage**      | (For `ventura_crawler`) Counts of data extracted by different methods (JSON-LD, Microdata, Adaptive, Fallback). | `ScrapingMetrics` (e.g., `json_ld_extractions`)                        | Shows which extraction methods are most effective for target sites. Shifts can indicate site structure changes. |

## 3. ETL Process Metrics

These metrics are specific to data transformation and loading processes, such as `etl_sqlite_to_mongo.py`.

| Metric Name                      | Description                                                                 | Source                                                              | Use/Interpretation                                                                                             |
|----------------------------------|-----------------------------------------------------------------------------|---------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| **Records Processed from Source**| Number of records read from the source database (e.g., SQLite).             | ETL script logs                                                     | Baseline for ETL input.                                                                                        |
| **Records Loaded to Target**     | Number of records successfully written to the target database (e.g., MongoDB).| ETL script logs, MongoDB write acknowledgements                     | Tracks successful data migration. Discrepancies with "Processed" indicate transformation/load errors.        |
| **Transformation Errors**        | Number of records that failed during the transformation stage (e.g., schema mapping, data type conversion). | ETL script logs                                                     | High numbers indicate issues with data consistency from scrapers or bugs in transformation logic.              |
| **Load Errors**                  | Number of records that failed during the loading stage into the target DB.  | ETL script logs, MongoDB error reports                              | Indicates issues with database connectivity, schema violations in target DB, or data integrity problems.        |
| **ETL Process Duration**         | Total time taken for the ETL process to complete.                           | ETL script logs, Orchestrator (Prefect task duration)               | Monitors ETL performance. Increases can signal data volume growth or inefficiencies.                             |
| **Data Validation Errors**       | (If applicable) Number of records failing schema validation before/during load. | ETL script logs, Pydantic validation errors (if used in ETL)        | Highlights data that doesn't conform to the expected target schema.                                            |
| **Duplicate Records Handled**    | Number of duplicate records identified and handled (e.g., skipped, updated via upsert). | ETL script logs (if explicitly tracked)                             | Important for understanding data overlap if sources provide redundant data or if ETL runs multiple times.      |

## 4. Orchestrator-Level Metrics (Prefect)

These metrics are primarily obtained from the Prefect Orion UI or its API.

| Metric Name                      | Description                                                                | Source                                   | Use/Interpretation                                                                                             |
|----------------------------------|----------------------------------------------------------------------------|------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| **Flow Run Status**              | Status of flow runs (Completed, Failed, Running, Scheduled, Crashed, Cancelled). | Prefect UI/API                             | Key indicator of overall pipeline health. Track failure rates per flow.                                        |
| **Task Run Status**              | Status of individual task runs within flows.                               | Prefect UI/API                             | Helps pinpoint specific points of failure within a workflow.                                                   |
| **Flow Run Duration (Avg/Max)**  | Average and maximum time taken for specific flows to complete.             | Prefect UI/API                             | Performance indicator for workflows. Trends can show degradation or improvement.                               |
| **Task Run Duration (Avg/Max)**  | Average and maximum time taken for specific tasks to complete.             | Prefect UI/API                             | Identifies bottlenecks within flows.                                                                           |
| **Task/Flow Retries**            | Number of automatic retries executed for tasks or flows.                   | Prefect UI/API                             | High retry counts can indicate intermittent issues or tasks that are barely succeeding.                        |
| **Work Queue Health**            | Metrics like queue length, number of active agents, agent heartbeat status.  | Prefect UI/API                             | Ensures the orchestration engine itself is healthy and has capacity to process tasks.                          |
| **Last Successful Run Timestamp**| Timestamp of the last successful completion for each critical flow.        | Prefect UI/API                             | Monitors if critical flows are running as scheduled and completing successfully. Alerts if too long since last success. |
| **Scheduled vs. Actual Start Time Lag** | Time difference between when a flow was scheduled to start and when it actually started. | Prefect UI/API (may require analysis)    | Indicates if there's contention for resources or agent availability issues.                                    |

## 5. Database Metrics

Monitoring the health and performance of the underlying databases (SQLite for `ventura_crawler`'s operational state, MongoDB for the main data store).

### a. MongoDB Metrics

| Metric Name                      | Description                                                                 | Source                                      | Use/Interpretation                                                                                             |
|----------------------------------|-----------------------------------------------------------------------------|---------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| **Document Count (per Collection)**| Number of documents in key collections (e.g., `unified_events`).            | MongoDB `countDocuments()`, monitoring tools| Tracks data growth and volume.                                                                                   |
| **Average Document Size**        | Average size of documents in collections.                                   | MongoDB `avgObjectSize`, monitoring tools   | Can indicate changes in data structure or verbosity.                                                           |
| **Query Latency (Avg/P95)**      | Time taken for common queries to execute.                                   | MongoDB profiler, APM, monitoring tools     | Critical for API performance if data is served. High latency indicates need for indexing or query optimization. |
| **Index Hit Rate / Miss Rate**   | Percentage of queries that use indexes effectively.                         | MongoDB `indexStats`, monitoring tools      | Low hit rates suggest missing or ineffective indexes, leading to slow queries.                                 |
| **Connections (Active/Available)**| Number of active database connections and available connections.            | MongoDB `serverStatus`, monitoring tools    | High connection counts or running out of connections can indicate issues.                                      |
| **Opcounters (Query/Insert/Update/Delete)** | Rate of database operations.                                                | MongoDB `serverStatus`, monitoring tools    | Shows database load and activity patterns.                                                                       |
| **Replication Lag**              | (If using replica sets) Delay between primary and secondary nodes.          | MongoDB `replSetGetStatus`, monitoring tools| Ensures data durability and read scalability. High lag is problematic.                                         |
| **Storage Size / Disk Usage**    | Total disk space used by the database and individual collections/indexes.   | MongoDB `dbStats`/`collStats`, OS tools     | For capacity planning and cost management.                                                                     |

### b. SQLite Metrics (for `ventura_crawler` operational DB)

| Metric Name                      | Description                                                                 | Source                                      | Use/Interpretation                                                                                             |
|----------------------------------|-----------------------------------------------------------------------------|---------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| **Database File Size**           | Total size of the SQLite database file (`serpentscale_scraper_data.db`).    | Filesystem                                  | Monitors disk usage; rapid growth might indicate issues or need for pruning.                                 |
| **Query Performance (Key Ops)**  | Latency for critical queries (e.g., cache lookup, proxy health update, selector pattern fetch). | Manual timing, application-level logging    | Important for `ventura_crawler`'s performance. Slow queries can bottleneck the scraper.                        |
| **Table Row Counts**             | Number of rows in `scraped_events`, `proxy_health`, `selector_patterns`.    | SQLite queries (`SELECT COUNT(*)`)          | Tracks the amount of operational data being stored.                                                            |
| **Write Lock Contention/Errors** | (If multiple processes access it, though less likely for typical Prefect setup) Frequency of "database is locked" errors. | Application logs (`DatabaseManager` retries) | Indicates concurrent access issues if SQLite is heavily used by multiple processes.                            |

## 6. Tools for Monitoring

*   **Prefect UI**: Primary tool for orchestrator-level metrics, flow/task status, logs.
*   **Logging Platform (e.g., ELK Stack, Grafana Loki, Datadog Logs)**: For aggregating and analyzing scraper, ETL, and application logs.
*   **Metrics Monitoring System (e.g., Prometheus with Grafana, Datadog, InfluxDB)**: For collecting, storing, and visualizing time-series metrics from all components. Scrapers and ETL scripts can expose metrics via client libraries.
*   **Database Monitoring Tools**:
    *   **MongoDB**: MongoDB Atlas Monitoring, Ops Manager, `mongostat`, `mongotop`, third-party tools.
    *   **SQLite**: Less built-in monitoring; relies on application-level logging of query performance and file size checks.
*   **Application Performance Monitoring (APM)**: Tools like Datadog APM, Sentry, Elastic APM can provide deeper insights into Python application performance.

By tracking these metrics, the project can maintain a high level of operational awareness, quickly identify and diagnose problems, and ensure the overall quality and reliability of the data pipeline.
